# ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting
[![arXiv](https://img.shields.io/badge/arXiv-2504.17524-b31b1b.svg)](https://arxiv.org/abs/2504.17524)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
This repository contains the PyTorch implementation of the paper **"ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting"**.
> **Code Availability:** The source code is available at [https://github.com/yqx7150/ESDiff](https://github.com/yqx7150/ESDiff)

## Abstract
Image inpainting is a technique used to restore missing or damaged regions of an image. Traditional methods primarily utilize information from adjacent pixels for reconstructing missing areas, while they struggle to preserve complex details and structures. Simultaneously, models based on deep learning necessitate substantial amounts of training data. To address this challenge, an encoding strategy-inspired diffusion model with few-shot learning for color image inpainting is proposed in this paper. The main idea of this novel encoding strategy is the deployment of a "virtual mask" to construct high-dimensional objects through mutual perturbations between channels. This approach enables the diffusion model to capture diverse image representations and detailed features from limited training samples. Moreover, the encoding strategy leverages redundancy between channels, integrates with low-rank methods during iterative inpainting, and incorporates the diffusion model to achieve accurate information output. Experimental results indicate that our method exceeds current techniques in quantitative metrics, and the reconstructed images quality has been improved in aspects oftexture and structural integrity, leading to more precise and coherent results.

Index Terms—Color image inpainting, encoding strategy, few-shot learning, diffusion model.'
<p align="center">
  <img src="assets/1.png" alt="ESDiff Overview" width="800">
  <br>
  <em>Figure 1: The pipeline of coded mask imaging in (a) and our encoding strategy introduced by a “virtual mask” in (b).</em>
</p>

## Method Overview
<p align="center">
  <img src="assets/2.png" alt="The specific process of mutual perturbation transformation." width="800">
  <br>
  <em>Figure 2: The specific process of mutual perturbation transformation. We perturb a virtual mask generated by a normal distribution and use the redundancy between the channels of the image to bring more changes and diversity to the color coding of the image, generating a more complex image representation and training Produce higher-dimensional, higher parameterized models.</em>
</p>

<p align="center">
  <img src="assets/4.png" alt="The pipeline of the prior learning stage in ESDiff." width="800">
  <br>
  <em>Figure 3: The pipeline of the prior learning stage in ESDiff. Before the prior learning of the score-based network, internal-middle patches are extracted 
from the original images and then perform various perturbations on the original patches.</em>
</p>

<p align="center">
  <img src="assets/5.png" alt="Reverse restoration process for the RG perturbation case. T" width="800">
  <br>
  <em>Figure 4: Reverse restoration process for the RG perturbation case. Through the saved virtual mask and the R channel image and G channel image disturbed by the G channel, we can restore the original image information.</em>
</p>


<p align="center">
  <img src="assets/6.png" alt="The pipeline of iteration inpainting procedure in ESDiff." width="800">
  <br>
  <em>Figure 5: The pipeline of iteration inpainting procedure in ESDiff. Three steps are contained in the procedure: Firstly, patches are extracted patch-by-patch from the observation after padding. Then, perform R-G perturbation, G-B perturbation, and B-R perturbation to obtain three different types of perturbation patches with a size of 64*64*3. Finally, the PC sampler, Inverse Perturbation, Low-rank step and DC steps are performed alternatively.</em>
</p>








